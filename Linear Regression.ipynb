{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Learning Python via ML  :D </h1><b> Creation of numpy array</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Arrray:\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "Zeros array:\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "data array:\n",
      "[1 2 3 4]\n",
      "constant full array:\n",
      "[[ 7.  7.]\n",
      " [ 7.  7.]]\n",
      "Identity Matrix:\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Random array:\n",
      "[[ 0.74583515  0.09280694]\n",
      " [ 0.18666792  0.30002827]]\n"
     ]
    }
   ],
   "source": [
    "# Getting started with numpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "arr1 = np.ones((2,2))\n",
    "print \"Ones Arrray:\\n\" ,arr1\n",
    "\n",
    "arr2 = np.zeros((2,2))\n",
    "print \"Zeros array:\\n\" , arr2\n",
    "\n",
    "arr3 = np.array([1,2,3,4])\n",
    "print \"data array:\\n\",arr3\n",
    "\n",
    "arr4 = np.full((2,2),7.0)\n",
    "print \"constant full array:\\n\",arr4\n",
    "\n",
    "arr5 = np.eye(2)\n",
    "print \"Identity Matrix:\\n\",arr5\n",
    "\n",
    "arr6= np.random.random((2,2))\n",
    "print \"Random array:\\n\",arr6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Slicing and dicing </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "a.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13 10  9]\n",
      " [19 26  5]\n",
      " [ 2 13  2]\n",
      " [23  5 13]]\n",
      "[170 232  89 211]\n",
      "Corr Label:\n",
      "[170 232  89 211]\n",
      "Training started\n",
      "Training Ended\n",
      "Predicted:\n",
      "[ 169.79786345  231.968206     89.16800761  211.12419249]\n",
      "Weights: [ 3.08079071  4.9276382   8.78915322  1.36882316]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Basic Linear regression class\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is a simple linear regression class. The idea is to familiarize the constructs of python, \n",
    "numpy and how to write efficient ml codes in python.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class LinearRegression(object):\n",
    "    weight = None\n",
    "    learningRate = 0.00001\n",
    "    def __init__(self,inputSize,learningRate=0.00001):\n",
    "        self.weight = np.zeros(inputSize+1)\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "    def predict(self,testInp):\n",
    "        finalOut = np.zeros(testInp.shape[0])\n",
    "        for idx in range(testInp.shape[0]): \n",
    "            finalOut[idx] = np.dot(np.append(testInp[idx],1.0) ,self.weight.transpose())\n",
    "        return finalOut\n",
    "\n",
    "    \"\"\"\n",
    "        trainX - should be a m x n matrix  \n",
    "        label -  should be n x 1 vector that contains the corresponding label of each training set\n",
    "        gd - represents the type of gradient descent to use 2 options now: \n",
    "            [i]  BGD - Batch Gradient Descent\n",
    "            [ii] SGD - Stochastic Gradient Descent (default)\n",
    "    \"\"\"\n",
    "    def train(self,trainX,label,numEpochs=100000):\n",
    "        print \"Training started\"\n",
    "        for i in range(numEpochs):\n",
    "            for idx in range(trainX.shape[0]):\n",
    "                trainingRow = np.append(trainX[idx],1.0)\n",
    "                thetaX = np.dot(trainingRow ,self.weight.transpose())\n",
    "                delta =  trainingRow * (thetaX - label[idx])\n",
    "                self.weight = self.weight - (self.learningRate * delta)\n",
    "        print \"Training Ended\"       \n",
    "                \n",
    "    def printWeights(self):\n",
    "        print \"Weights:\",self.weight\n",
    "                \n",
    "    def plot(self,trainX,label):\n",
    "        figsize(40,50)\n",
    "        plt.xlabel(\"Index\")\n",
    "        plt.ylabel(\"Predicted Output\")\n",
    "        plt.xlim(5)\n",
    "        pred = self.predict(trainX)\n",
    "        xCoords = [i+1 for i in range(trainX.shape[0]+1)]\n",
    "        plt.plot(xCoords,pred,color='r')\n",
    "        plt.plot(xCoords,label,color='b')\n",
    "        #plt.show()\n",
    "\n",
    "# Let's test\n",
    "\n",
    "randInp = np.random.randint(2,30,size=(4,3))\n",
    "print randInp\n",
    "def fx(inp):\n",
    "    return np.dot(inp , np.array([3,5,9]).transpose())\n",
    "labelOut = fx(randInp)\n",
    "print labelOut\n",
    "#print \"Random Input\\n\", randInp\n",
    "\n",
    "print \"Corr Label:\\n\",labelOut\n",
    "\n",
    "#print \"Let's start Training ..\"\n",
    "\n",
    "reg = LinearRegression(3)\n",
    "reg.train(randInp,labelOut)\n",
    "\n",
    "print \"Predicted:\\n\",reg.predict(randInp)\n",
    "\n",
    "print reg.printWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression implementation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "class LogisticRegression(object):\n",
    "    weight  = None\n",
    "    def __init__(self,numInput,learningRate=0.0001):\n",
    "        self.weight = np.zeros(numInput+1)\n",
    "        self.learningRate = learningRate\n",
    "    \n",
    "    def sigmoid(inp):\n",
    "        return 1/1+exp(-inp)\n",
    "    \n",
    "    def predict(self,testInp):\n",
    "        finalOut = np.zeros(testInp.shape[0])\n",
    "        for idx in range(testInp.shape[0]):\n",
    "            finalOut[idx] = np.dot(np.append(testInp[idx],1.0),self.weight.transpose())\n",
    "        return finalOut\n",
    "    \n",
    "    def train(self,trainX,label,numEpochs=1000):\n",
    "        print \"Training started\"\n",
    "        for i in range(numEpochs):\n",
    "            for idx in range(trainX.shape[0]):\n",
    "                trainingRow = np.append(trainX[idx],1.0)\n",
    "                thetaX = sigmoid(np.dot(trainingRow ,self.weight.transpose())) # Here h(x) is sigmoid as compared to theta*X of linear regression\n",
    "                delta =  trainingRow * (thetaX - label[idx])\n",
    "                self.weight = self.weight - (self.learningRate * delta)\n",
    "        print \"Training Ended\"   \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax regression \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
